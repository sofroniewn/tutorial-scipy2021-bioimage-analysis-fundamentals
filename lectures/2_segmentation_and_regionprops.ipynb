{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%gui qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import time\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation\n",
    "\n",
    "--------------\n",
    "\n",
    "## Separating an image into one or more regions of interest.\n",
    "\n",
    "Everyone has heard or seen Photoshop or a similar graphics editor take a person from one image and place them into another.  The first step of doing this is *identifying where that person is in the source image*.\n",
    "\n",
    "In popular culture, the Terminator's vision segments humans out of the overall scene:\n",
    "\n",
    "<img src=\"../images/terminator-vision.png\" width=\"700px\"/>\n",
    "\n",
    "Segmentation is a fundamental operation in scientific image analysis because we often want to measure properties of real, physical *objects* such as cells embedded in our image. As such, we want to find those objects within our image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computationally, segmentations are most often represented as images, of the same size as the original image, containing integer *labels*, with one value representing one object.\n",
    "\n",
    "Here is a very simple image and segmentation, taken from [this scikit-image tutorial](https://scikit-image.org/docs/dev/auto_examples/segmentation/plot_watershed.html#sphx-glr-auto-examples-segmentation-plot-watershed-py):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "import napari\n",
    "\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "\n",
    "\n",
    "# Generate an initial image with two overlapping circles\n",
    "x, y = np.indices((80, 80))\n",
    "x1, y1, x2, y2 = 28, 28, 44, 52\n",
    "r1, r2 = 16, 20\n",
    "mask_circle1 = (x - x1)**2 + (y - y1)**2 < r1**2\n",
    "mask_circle2 = (x - x2)**2 + (y - y2)**2 < r2**2\n",
    "image = np.logical_or(mask_circle1, mask_circle2)\n",
    "\n",
    "# Now we want to separate the two objects in image\n",
    "# Generate the markers as local maxima of the distance to the background\n",
    "distance = ndi.distance_transform_edt(image)\n",
    "coords = peak_local_max(distance, footprint=np.ones((3, 3)), labels=image)\n",
    "mask = np.zeros(distance.shape, dtype=bool)\n",
    "mask[tuple(coords.T)] = True\n",
    "markers, _ = ndi.label(mask)\n",
    "labels = watershed(-distance, markers, mask=image)\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "image_layer = viewer.add_image(image)\n",
    "labels_layer = viewer.add_labels(labels)\n",
    "labels_as_image_layer = viewer.add_image(\n",
    "    labels, name='labels as image'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that \"labels\" is just a NumPy array with integer values. We have to be careful to interpret it as labels and not as an image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmenting nuclei and measuring cell properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the rest of this notebook, we will segment nuclei from a small sample image provided by the Allen Institute for Cell Science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclei = io.imread('../images/cells.tif')\n",
    "membranes = io.imread('../images/cells_membrane.tif')\n",
    "\n",
    "print(\"shape: {}\".format(nuclei.shape))\n",
    "print(\"dtype: {}\".format(nuclei.dtype))\n",
    "print(\"range: ({}, {})\".format(np.min(nuclei), np.max(nuclei)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pixel spacing in this dataset is 0.29µm in the z (leading!) axis, and 0.26µm in the x and y axes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacing = np.array([0.29, 0.26, 0.26])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view the 3D image using napari."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.view_image(\n",
    "    nuclei,\n",
    "    contrast_limits=[0, 1],\n",
    "    scale=spacing,\n",
    "    ndisplay=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "from napari.utils.notebook_display import nbscreenshot\n",
    "\n",
    "viewer.ndisplay = 3\n",
    "viewer.camera.angles = (-30, 25, 120)\n",
    "nbscreenshot(viewer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge detection\n",
    "\n",
    "We saw the [Sobel operator](https://en.wikipedia.org/wiki/Sobel_operator) in the filters lesson. It is an edge detection algorithm that approximates the gradient of the image intensity, and is fast to compute. The [Scharr filter](https://scikit-image.org/docs/dev/api/skimage.filters.html#skimage.filters.scharr) is a slightly more sophisticated version, with smoothing weights [3, 10, 3]. Both work for n-dimensional images in scikit-image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = filters.scharr(nuclei)\n",
    "\n",
    "nuclei_layer = viewer.layers['nuclei']\n",
    "nuclei_layer.blending = 'additive'\n",
    "nuclei_layer.colormap = 'green'\n",
    "\n",
    "viewer.add_image(\n",
    "    edges,\n",
    "    scale=spacing,\n",
    "    blending='additive',\n",
    "    colormap='magenta',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input",
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "nbscreenshot(viewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised = ndi.median_filter(nuclei, size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thresholding\n",
    "\n",
    "[Thresholding](https://en.wikipedia.org/wiki/Thresholding_%28image_processing%29) is used to create binary images. A threshold value determines the intensity value separating foreground pixels from background pixels. Foregound pixels are pixels brighter than the threshold value, background pixels are darker. In many cases, images can be adequately segmented by thresholding followed by labelling of *connected components*, which is a fancy way of saying \"groups of pixels that touch each other\".\n",
    "\n",
    "Different thresholding algorithms produce different results. [Otsu's method](https://en.wikipedia.org/wiki/Otsu%27s_method) and [Li's minimum cross entropy threshold](https://scikit-image.org/docs/dev/auto_examples/developers/plot_threshold_li.html) are two common algorithms. Below, we use Li. You can use `skimage.filters.threshold_<TAB>` to find different thresholding methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li_thresholded = denoised > filters.threshold_li(denoised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.add_image(\n",
    "    li_thresholded,\n",
    "    scale=spacing,\n",
    "    opacity=0.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "nbscreenshot(viewer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Morphological operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Mathematical morphology](https://en.wikipedia.org/wiki/Mathematical_morphology) operations and structuring elements are defined in `skimage.morphology`. Structuring elements are shapes which define areas over which an operation is applied. The response to the filter indicates how well the neighborhood corresponds to the structuring element's shape.\n",
    "\n",
    "There are a number of two and three dimensional structuring elements defined in `skimage.morphology`. Not all 2D structuring element have a 3D counterpart. The simplest and most commonly used structuring elements are the `disk`/`ball` and `square`/`cube`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions operating on [connected components](https://en.wikipedia.org/wiki/Connected_space) can remove small undesired elements while preserving larger shapes.\n",
    "\n",
    "`skimage.morphology.remove_small_holes` fills holes and `skimage.morphology.remove_small_objects` removes bright regions. Both functions accept a size parameter, which is the minimum size (in pixels) of accepted holes or objects. It's useful in 3D to think in linear dimensions, then cube them. In this case, we remove holes / objects of the same size as a cube 20 pixels across."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import morphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 20\n",
    "\n",
    "remove_holes = morphology.remove_small_holes(\n",
    "    li_thresholded, width ** 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 20\n",
    "\n",
    "remove_objects = morphology.remove_small_objects(\n",
    "    remove_holes, width ** 3\n",
    ")\n",
    "\n",
    "viewer.add_image(\n",
    "    remove_objects,\n",
    "    name='cleaned',\n",
    "    scale=spacing,\n",
    "    opacity=0.3,\n",
    ");\n",
    "\n",
    "viewer.layers['li_thresholded'].visible = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "nbscreenshot(viewer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to label the connected components of this image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import measure\n",
    "\n",
    "labels = measure.label(remove_objects)\n",
    "\n",
    "viewer.add_labels(\n",
    "    labels,\n",
    "    scale=spacing,\n",
    "    opacity=0.5,\n",
    ")\n",
    "\n",
    "viewer.layers['cleaned'].visible = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "nbscreenshot(viewer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that tightly packed cells connected in the binary image are assigned the same label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better segmentation would assign different labels to different nuclei. \n",
    "\n",
    "Typically we use [watershed segmentation](https://en.wikipedia.org/wiki/Watershed_%28image_processing%29) for this purpose. We place *markers* at the centre of each object, and these labels are expanded until they meet an edge or an adjacent marker.\n",
    "\n",
    "The trick, then, is how to find these markers. It can be quite challenging to find markers with the right location. A slight amount of noise in the image can result in very wrong point locations. Here is a common approach: find the distance from the object boundaries, then place points at the maximal distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = ndi.distance_transform_edt(remove_objects, sampling=spacing)\n",
    "\n",
    "maxima = morphology.local_maxima(transformed)\n",
    "viewer.add_points(\n",
    "    np.transpose(np.nonzero(maxima)) * spacing,  # don't forget scale\n",
    "    name='bad points',\n",
    "    size=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "nbscreenshot(viewer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that these points are actually terrible, with many markers found within each nuclei.\n",
    "\n",
    "There are many approaches to find better points, but with napari, in many cases, a little interactivity can quickly get us the segmentation we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer.layers['bad points'].visible = False\n",
    "viewer.dims.ndisplay = 2\n",
    "viewer.dims.set_point(0, 30 * spacing[0])\n",
    "\n",
    "points = viewer.add_points(\n",
    "    name='interactive points',\n",
    "    ndim=3,\n",
    "    size=1,\n",
    ")\n",
    "points.mode = 'add'\n",
    "\n",
    "\n",
    "# now, we annotate the centers of the nuclei in your image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "viewer.dims.ndisplay = 3\n",
    "viewer.camera.angles = (-30, 25, 120)\n",
    "nbscreenshot(viewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# scaled points.data\n",
    "\n",
    "points.data = np.array(\n",
    "      [[ 8.7       ,  3.10175426,  7.22127134],\n",
    "       [ 8.7       ,  8.31173204, 21.63958194],\n",
    "       [ 8.7       ,  2.85942971, 38.48113801],\n",
    "       [ 8.7       , 11.34078889, 46.23552354],\n",
    "       [ 8.7       , 12.06776253, 58.83640003],\n",
    "       [ 8.7       , 18.97401214, 29.39396747],\n",
    "       [ 8.7       , 25.03212584, 42.11600623],\n",
    "       [ 8.7       , 25.03212584, 64.89451373],\n",
    "       [ 8.7       , 36.30021731, 62.10778143],\n",
    "       [ 8.7       , 36.17905504, 48.90109357],\n",
    "       [ 8.7       , 41.63135737, 27.09188426],\n",
    "       [ 8.7       , 22.85120491, 13.52170958],\n",
    "       [ 8.7       , 35.57324367, 11.21962638],\n",
    "       [ 8.7       , 49.99155427, 12.79473594],\n",
    "       [ 8.7       , 57.38245298, 20.06447238],\n",
    "       [ 8.7       , 61.98661939, 36.78486618],\n",
    "       [ 8.7       , 53.98990931, 45.62971217],\n",
    "       [ 8.7       , 64.65218941, 53.02061088],\n",
    "       [ 8.7       , 57.50361525, 63.44056644]],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell",
     "remove-input",
     "remove-output"
    ]
   },
   "outputs": [],
   "source": [
    "# unscaled points.data\n",
    "\n",
    "# points.data = np.array(\n",
    "#       [[ 30.        ,  14.2598685 ,  27.7741219 ],\n",
    "#        [ 30.        ,  30.10416663,  81.36513029],\n",
    "#        [ 30.        ,  13.32785096, 144.27631406],\n",
    "#        [ 30.        ,  46.8804823 , 191.80920846],\n",
    "#        [ 30.        ,  43.15241215, 211.84758551],\n",
    "#        [ 30.        ,  94.87938547, 160.12061219],\n",
    "#        [ 30.        ,  72.97697335, 112.58771779],\n",
    "#        [ 30.        , 138.21820096, 189.01315585],\n",
    "#        [ 30.        , 144.74232372, 242.60416424],\n",
    "#        [ 30.        ,  98.14144685, 251.92433962],\n",
    "#        [ 30.        , 153.59649032, 112.58771779],\n",
    "#        [ 30.        , 134.49013081,  40.35635865],\n",
    "#        [ 30.        , 182.95504275,  48.74451649],\n",
    "#        [ 30.        , 216.04166532,  80.89912152],\n",
    "#        [ 30.        , 235.14802483, 130.296051  ],\n",
    "#        [ 30.        , 196.00328827, 169.44078757],\n",
    "#        [ 30.        , 245.86622651, 202.06140137],\n",
    "#        [ 30.        , 213.71162148, 250.52631331],\n",
    "#        [ 28.        ,  87.42324517,  52.00657787]],\n",
    "#       dtype=float,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have marked all the points, you can grab the data back, and make a markers image for `skimage.segmentation.watershed`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import segmentation\n",
    "\n",
    "marker_locations = points.data / spacing\n",
    "\n",
    "markers = np.zeros(nuclei.shape, dtype=np.uint32)\n",
    "marker_indices = tuple(np.round(marker_locations).astype(int).T)\n",
    "markers[marker_indices] = np.arange(len(marker_locations)) + 1\n",
    "markers_big = morphology.dilation(markers, morphology.ball(5))\n",
    "\n",
    "segmented = segmentation.watershed(\n",
    "    edges,\n",
    "    markers_big,\n",
    "    mask=remove_objects,\n",
    ")\n",
    "\n",
    "viewer.add_labels(\n",
    "    segmented,\n",
    "    scale=spacing,\n",
    ")\n",
    "\n",
    "viewer.layers['labels'].visible = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "nbscreenshot(viewer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After watershed, we have better disambiguation between internal cells!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have defined our objects, we can make measurements on them using `skimage.measure.regionprops` and the new `skimage.measure.regionprops_table`. These measurements include features such as area or volume, bounding boxes, and intensity statistics.\n",
    "\n",
    "Before measuring objects, it helps to clear objects from the image border. Measurements should only be collected for objects entirely contained in the image.\n",
    "\n",
    "Given the layer-like structure of our data, we only want to clear the objects touching the sides of the volume, but not the top and bottom, so we pad and crop the volume along the 0th axis to avoid clearing the mitotic nucleus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmented_padded = np.pad(\n",
    "    segmented,\n",
    "    ((1, 1), (0, 0), (0, 0)),\n",
    "    mode='constant',\n",
    "    constant_values=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interior_labels = segmentation.clear_border(segmented_padded)[1:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`skimage.measure.regionprops` automatically measures many labeled image features. Optionally, an `intensity_image` can be supplied and intensity features are extracted per object. It's good practice to make measurements on the original image.\n",
    "\n",
    "Not all properties are supported for 3D data. Below are lists of supported and unsupported 3D measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regionprops = measure.regionprops(interior_labels, intensity_image=nuclei)\n",
    "\n",
    "supported = [] \n",
    "unsupported = []\n",
    "\n",
    "for prop in regionprops[0]:\n",
    "    try:\n",
    "        regionprops[0][prop]\n",
    "        supported.append(prop)\n",
    "    except NotImplementedError:\n",
    "        unsupported.append(prop)\n",
    "\n",
    "print(\"Supported properties:\")\n",
    "print(\"  \" + \"\\n  \".join(supported))\n",
    "print()\n",
    "print(\"Unsupported properties:\")\n",
    "print(\"  \" + \"\\n  \".join(unsupported))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`skimage.measure.regionprops` ignores the 0 label, which represents the background."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`regionprops_table` returns a dictionary of columns compatible with creating a pandas dataframe of properties of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "info_table = pd.DataFrame(\n",
    "    measure.regionprops_table(\n",
    "        interior_labels,\n",
    "        intensity_image=nuclei,\n",
    "        properties=['label', 'slice', 'area', 'mean_intensity', 'solidity'],\n",
    "    )\n",
    ").set_index('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use pandas and seaborn for some analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.scatterplot(x='area', y='solidity', data=info_table, hue='mean_intensity');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the mitotic nucleus is a clear outlier from the others in terms of solidity and intensity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge problems\n",
    "\n",
    "Put your 3D image processing skills to the test by working through these challenge problems.\n",
    "\n",
    "### Improve the segmentation\n",
    "\n",
    "A few objects were oversegmented in the declumping step. Try to improve the segmentation and assign each object a single, unique label. You can try to use [calibrated denoising](https://scikit-image.org/docs/dev/auto_examples/filters/plot_j_invariant.html) to get smoother nuclei and membrane images.\n",
    "\n",
    "### Segment cell membranes\n",
    "\n",
    "Try segmenting the accompanying membrane channel. In the membrane image, the membrane walls are the bright web-like regions. This channel is difficult due to a high amount of noise in the image. Additionally, it can be hard to determine where the membrane ends in the image (it's not the first and last planes).\n",
    "\n",
    "Below is a 2D segmentation of the membrane:\n",
    "\n",
    "![](../_images/membrane_segmentation.png)\n",
    "\n",
    "Hint: there should only be one nucleus per membrane.\n",
    "\n",
    "### Measure the area in µm³ of the cells\n",
    "\n",
    "Once you have segmented the cell membranes, use regionprops to measure the distribution of cell areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
